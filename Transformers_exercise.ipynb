{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefanogiagu/corsoSSAS_2024/blob/main/Transformers_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Machine Learning for Physics 2022-2023\n",
        "## Hands-on session 4 (Transformers)\n",
        "\n",
        "In this and next hadns-on sessions, we will try to implement a transformer architecture and to train it for a tipical high energy physics task: jet tagging (e.g. classification of jets originating from different particles: *gluons, quarks, Ws, Zs, and top quarks*.\n",
        "\n",
        "**Physics context:** <p>\n",
        "At the extreme energies of the Large Hadron Collider, massive particles can be produced with such high Lorentz boost that their decays into hadrons (hadron jets) are collimated in such a way that the resulting particles overlap. Deducing whether the substructure of an observed jet is due to a single low-mass particle or to multiple decay objects of a high-mass particle is an important problem in LHC data analysis. Traditional approaches are based on high-level observables built from theoretical models of energy deposition in calorimeters and charged tracks parameters reconsrtcuted in the inner tracker, but the complexity of the data makes this task an excellent candidate for the application of deep learning tools. The jet constituents can be in fact represented either as 2D or 3D images,lending itself to the natural application of image classification techniques (CNN, ViT etc.), or as pointclouds/graphs, that can be classified with GNNs, or as sequences, that can be analysed by RNNs or Transformers.\n",
        "\n",
        "\n",
        "**Dataset:** <p>\n",
        "The dataset is the *JetDataset*: you can find a description in [this presentation](https://docs.google.com/presentation/d/1dHhPSFPlhy332SIJnmu5kwHRd0jvReKsr6ma0Cgnrac/edit?usp=sharing)\n",
        "\n",
        "\n",
        "**Transfortmer Architecture:** <p>\n",
        "\n",
        "We implements the original transformer architecture of *A.Vaswani et al. “Attention is All You Need” (2017) [arXiv:1706.03762](https://arxiv.org/abs/1706.03762)*, by using only the transformer-encoder part, with multi-head attentions+MLP blocks. We also adopt a pre-layer normalization (in addition to the original post-layer normalization) as suggested by *R.Xiong et al. \"On Layer Normalization in the Transformer Architecture\" (2020) [pdf](http://proceedings.mlr.press/v119/xiong20b/xiong20b.pdf)*.  \n",
        "\n",
        "The implementation is done using pure [PyTorch](https://pytorch.org) APIs.\n",
        "\n",
        "For infos, latest version of the notebook, etc., contact Stefano Giagu: email: <stefano.giagu@uniroma1.it>, web: [https://www.giagu.it](https://www.giagu.it)"
      ],
      "metadata": {
        "id": "lutugMEOKNbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import h5py\n",
        "import glob\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "CDxOrcBkSu6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset download\n",
        "# we'll clone a github repository from M. Pierini containing the dataset\n",
        "! git clone https://github.com/pierinim/tutorials.git\n",
        "! ls tutorials/Data/JetDataset/"
      ],
      "metadata": {
        "id": "4WUQ-3hLgrwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define device to use (cpu/gpu)\n",
        "if torch.cuda.is_available():\n",
        "  print('# of GPUs available: ', torch.cuda.device_count())\n",
        "  print('First GPU type: ',torch.cuda.get_device_name(0))\n",
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Computation device: {device}\\n\")"
      ],
      "metadata": {
        "id": "HkMJUvygk0AV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Handling\n",
        "\n",
        "The dataset consists of a list of jets. For each jet, we have up to 100 particles (zero-padding is used in case a jet has less than 100 particles).\n",
        "\n",
        "For each particle, we have 16 features:\n",
        "\n",
        "* the four-momentum in cartesian coordinates $(p_x,p_y,p_z,E)$\n",
        "* the energy divided by the jet energy ($E_{rel}$)\n",
        "* the transverse momentum ($p_T$), i.e. the momentum projected on the plane transverse to proton beams\n",
        "* the momentum transverse to the jet direction ($p_{Trel}$)\n",
        "* the pseudorapidity ($\\eta$), a function of the polar angle (see https://en.wikipedia.org/wiki/Pseudorapidity)\n",
        "* the pseudorapidity relative to the jet direction ($\\eta_{rel}$)\n",
        "* the pseudorapidity relative to the jet direction ($\\eta_{rot}$) after a rotation is applied so that the jet image looks vertical\n",
        "* the azimuth angle ($\\phi$)\n",
        "* the azimuth angle relative to the jet direction ($\\phi_{rel}$)\n",
        "* the azimuth angle relative to the jet direction ($\\phi_{rot}$) after a rotation is applied so that the jet image looks vertical\n",
        "\n",
        "The ground truth is incorporated in a ['j_g', 'j_q', 'j_w', 'j_z', 'j_t] vector of boolean, taking the form:\n",
        "\n",
        "* $[1, 0, 0, 0, 0]$ for gluons\n",
        "* $[0, 1, 0, 0, 0]$ for quarks\n",
        "* $[0, 0, 1, 0, 0]$ for W bosons (with W  qq)\n",
        "* $[0, 0, 0, 1, 0]$ for Z bosons (with Z  qq)\n",
        "* $[0, 0, 0, 0, 1]$ for top quarks (with t  Wq  qqq)\n",
        "\n",
        "This is what is called 'one-hot' encoding of a discrete label (typical of ground truth for classification problems)."
      ],
      "metadata": {
        "id": "yT-JiCxY-7HY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data is stored in hirearchical data format (h5), a file format desgined to store and maniuplate large size data structures\n",
        "# .h5 files can be accesses in python using the h5py library (https://docs.h5py.org/en/stable/)\n",
        "\n",
        "# read dataset (only 50k events to keep training time ~20' on google colab, better performance can be obtained adding the three commented files\n",
        "target = np.array([])\n",
        "p_data = np.array([])\n",
        "datafiles = [#'tutorials/Data/JetDataset/jetImage_7_100p_80000_90000.h5',\n",
        "             #'tutorials/Data/JetDataset/jetImage_7_100p_70000_80000.h5',\n",
        "             #'tutorials/Data/JetDataset/jetImage_7_100p_60000_70000.h5',\n",
        "             'tutorials/Data/JetDataset/jetImage_7_100p_50000_60000.h5',\n",
        "             'tutorials/Data/JetDataset/jetImage_7_100p_40000_50000.h5',\n",
        "             'tutorials/Data/JetDataset/jetImage_7_100p_30000_40000.h5',\n",
        "             'tutorials/Data/JetDataset/jetImage_7_100p_10000_20000.h5',\n",
        "             'tutorials/Data/JetDataset/jetImage_7_100p_0_10000.h5']\n",
        "\n",
        "\n",
        "# let's print what is contained in one of the files:\n",
        "f = h5py.File(datafiles[0])\n",
        "print(list(f.keys()))\n",
        "f.close()\n",
        "\n",
        "# each file contains different numpy arrays, the ones we are interested in are:\n",
        "# \"jetConstituentsList\": containing for each jet, and for each jet constituent particle (up to 100 particles) the 16 features associated to the jet particle\n",
        "# \"jets\": containing for each jet several (59) global features of the jet, we are here interested in the elements from -6:-1 that provide a onehot encoding of the jet-type label ['j_g', 'j_q', 'j_w', 'j_z', 'j_t]\n",
        "\n",
        "\n",
        "#loop over the files and concatenate the content to the p_adat and target arrays\n",
        "for fileIN in datafiles:\n",
        "    print(\"Appending %s\" %fileIN)\n",
        "    f = h5py.File(fileIN) #read the h5 file\n",
        "    data = np.array(f.get(\"jetConstituentList\")) #jet constituents\n",
        "    targ = np.array(f.get('jets')[0:,-6:-1])  #select ['j_g', 'j_q', 'j_w', 'j_z', 'j_t] out of the 59 features presents in the container\n",
        "    p_data = np.concatenate([p_data, data], axis=0) if p_data.size else data\n",
        "    target = np.concatenate([target, targ], axis=0) if target.size else targ\n",
        "    del data, targ\n",
        "    f.close()\n",
        "\n",
        "print(target.shape, p_data.shape)\n",
        "\n",
        "p_featurenames = ['j1_px','j1_py','j1_pz','j1_e','j1_erel','j1_pt','j1_ptrel',\n",
        " 'j1_eta','j1_etarel','j1_etarot','j1_phi','j1_phirel','j1_phirot',\n",
        " 'j1_deltaR','j1_costheta','j1_costhetarel']\n",
        "\n",
        "print(p_featurenames)"
      ],
      "metadata": {
        "id": "ecaFQsvJguQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the information for one of the jets\n",
        "\n",
        "labels = ['gluon', 'quark', 'W', 'Z', 'top']\n",
        "\n",
        "print('target: ', target[0])\n",
        "print('so it\\'s a jet of type: ',  labels[np.argmax(target[0])])\n",
        "print()\n",
        "\n",
        "print('jet - particle 0 - pT / eta / phi: ', p_data[0,0,5], ' / ', p_data[0,0,7], ' / ', p_data[0,0,10])\n"
      ],
      "metadata": {
        "id": "tEFNTtyCQZmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this function makes the histogram of a given quantity for the five classes\n",
        "def makePlot_p(feature_index, input_data, input_featurenames, labels):\n",
        "    plt.subplots()\n",
        "    for i in range(len(labels)):\n",
        "        my_data = input_data[:,:,feature_index]\n",
        "        # notice the use of numpy masking to select specific classes of jets\n",
        "        my_data = my_data[np.argmax(target, axis=1) == i]\n",
        "        # then plot the right quantity for the reduced array\n",
        "        plt.hist(my_data[:,feature_index].flatten(), 50, density=True, histtype='step', fill=False, linewidth=1.5)\n",
        "    plt.yscale('log', nonpositive='clip', )\n",
        "    plt.legend(labels, fontsize=12, frameon=False)\n",
        "    plt.xlabel(input_featurenames[feature_index], fontsize=15)\n",
        "    plt.ylabel('Prob. Density (a.u.)', fontsize=15)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Ha0fqEy0g7W9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we now plot all the features\n",
        "for i in range(len(p_featurenames)):\n",
        "    makePlot_p(i, p_data, p_featurenames, labels)"
      ],
      "metadata": {
        "id": "TV3uDYvzg-NA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:** convert the target array in one-hot labels\n",
        "\n",
        "**Tipp:**\n",
        "Use the np.argmax ..."
      ],
      "metadata": {
        "id": "ANzq_Z3An-kQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert one-hot lables in integers labels, and split data\n",
        "\n",
        "p_label = # ... TO DO\n",
        "\n",
        "data_notnorm = np.array(p_data)\n",
        "\n",
        "# training, validation, test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "training_frac = 0.6 # training set fraction wrt whole sample\n",
        "testset_frac = 0.25 # test set fraction wrt validation set\n",
        "\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(data_notnorm,p_label,train_size=training_frac, shuffle=True, random_state=1234)\n",
        "X_vali,X_test,Y_vali,Y_test = train_test_split(X_test,Y_test,test_size=testset_frac, shuffle=True, random_state=1234)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_vali.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_vali.shape)\n",
        "print(Y_test.shape)"
      ],
      "metadata": {
        "id": "ykA5LusNT9ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:** normalize input features in N(0,1)\n",
        "\n",
        "**Tipp:**\n",
        "Use the  sklearn.preprocessing.StandardScaler"
      ],
      "metadata": {
        "id": "F6w4DI6booBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize data\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler ,StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "#NOTE: StandardScaler works with (nevents, features) shaped arrays so let's convert (N, 100, 16) -> (N*100, 16) and back\n",
        "X_train_norm = # ... TO DO\n",
        "X_vali_norm = # ... TO DO\n",
        "X_test_norm = # ... TO DO\n",
        "print(X_train_norm.shape)\n",
        "print(X_vali_norm.shape)\n",
        "print(X_test_norm.shape)"
      ],
      "metadata": {
        "id": "ElK9If1RoNtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:** convert the numpy arrays in torch tensors\n",
        "\n",
        "**Tipp:**\n",
        "Use the troch.Tensor(numpy vector).float() or .int() methods\n"
      ],
      "metadata": {
        "id": "pbNnonWLDNKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert numpy arrays to torch tensors\n",
        "\n",
        "data_tr = # ... TO DO\n",
        "label_tr = # ... TO DO\n",
        "data_va = # ... TO DO\n",
        "label_va = # ... TO DO\n",
        "data_te = # ... TO DO\n",
        "label_te = # ... TO DO\n",
        "\n",
        "print(data_tr.shape)\n",
        "print(label_tr.shape)\n",
        "print(data_va.shape)\n",
        "print(label_va.shape)\n",
        "print(data_te.shape)\n",
        "print(label_te.shape)"
      ],
      "metadata": {
        "id": "gaMO6ST1hClL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:** create torch dataset and dataloaders\n",
        "\n",
        "**Tipp:**\n",
        "Use torch.utils.data.TensorDataset and torch.utils.data.DataLoader methods\n",
        "\n",
        "NOTE: for the DataLoader of the traing set use the *shuffle=True*, and *drop_last=True* arguments"
      ],
      "metadata": {
        "id": "WC2uA_ABENOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch datasets\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "dataset_tr = # ... TO DO TensorDataset(...)\n",
        "dataset_va = # ... TO DO\n",
        "dataset_te = # ... TO DO\n",
        "\n",
        "print(len(dataset_tr))\n",
        "print(len(dataset_va))\n",
        "print(len(dataset_te))"
      ],
      "metadata": {
        "id": "Z2_3lpSvhFe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch dataloader/batching\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch=64 #batch size\n",
        "\n",
        "train_loader = # ... TO DO DataLoader(...)\n",
        "val_loader = # ... TO DO\n",
        "test_loader = # ... TO DO\n",
        "\n",
        "print(len(train_loader))\n",
        "print(len(val_loader))\n",
        "print(len(test_loader))"
      ],
      "metadata": {
        "id": "fGL1NKatjP-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer architecture\n",
        "\n",
        "We define two python classes inheriting from pytroch nn.Module:\n",
        "\n",
        "* *AttentionBlock*: implements the standard attention (multi-head attention + MLP) block for a tranformer encoder architecture\n",
        "* *MyTransformer*: a classifier based on a transformer encoder architecture implementation"
      ],
      "metadata": {
        "id": "lIQRu9bZ_3A_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1:** for the AttentionBlock define an *mlp* block made by a Linear layer with GELU activation, a dropout layer, another Linear layer w/o activation floowed by another dropout layer.\n",
        "\n",
        "The *mlp* takes in input a tensor with dimension *embed_dim*, and output a tensor with the same dimension. The hidden layers have *hidden_dim* neurons. The two dropout layers uses the same *dropout* probability.\n",
        "\n",
        "**Tipp:**\n",
        "Use a nn.Sequential() model for the mlp containing nn.Linear, nn.GELU, nn.Dropout layers."
      ],
      "metadata": {
        "id": "FqHJMNADFP2p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "756AtlAZLFfX"
      },
      "outputs": [],
      "source": [
        "class AttentionBlock(nn.Module):\n",
        "    #  Implements the standard attention (multi-head attention + MLP) block for\n",
        "    #  a tranformer encoder architecture\n",
        "\n",
        "    #  structure:\n",
        "    #   MHA: pre layer normalization (see Ruibin Xiong et al. (2020)) + multi-head attention (pytorch implementation) + layer normalization\n",
        "    #   MLP: dense + gelu + droput + dense + dropout\n",
        "\n",
        "    #  arguments:\n",
        "    #   embed_dim  - Dimensionality of input and attention feature vectors\n",
        "    #   hidden_dim - Dimensionality of hidden layer in feed-forward network\n",
        "    #                (usually 2-4x larger than embed_dim)\n",
        "    #   num_heads  - Number of heads to use in the Multi-Head Attention block\n",
        "    #   dropout    - Amount of dropout to apply in the feed-forward network\n",
        "\n",
        "    #    ^\n",
        "    #    |_____    NOR2(x) + NOR2(MHA(NOR1(x))) + MLP(NOR2(MHA(NOR1(x)))): output (L,B,embde_dim)\n",
        "    #    |     ^\n",
        "    #  -----   |\n",
        "    # | MLP |  |\n",
        "    #  -----   |\n",
        "    #    |_____|\n",
        "    #    |\n",
        "    #  -----\n",
        "    # | NOR |\n",
        "    #  -----\n",
        "    #    |_____    x + MHA(NOR1(x))\n",
        "    #    |     ^\n",
        "    #  -----   |\n",
        "    # | MHA |  |\n",
        "    #  -----   |\n",
        "    #    |     |\n",
        "    #  -----   |\n",
        "    # | NOR |  |\n",
        "    #  -----   |\n",
        "    #    |_____|\n",
        "    #    |        x\n",
        "\n",
        "    def __init__(self, embed_dim, hidden_dim, num_heads, dropout=0.0):\n",
        "        super(AttentionBlock, self).__init__()\n",
        "\n",
        "        self.layer_norm_1 = nn.LayerNorm(embed_dim)\n",
        "        self.attn = nn.MultiheadAttention(embed_dim, num_heads) #this pytroch function implements a full MH-Attention block (see https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html)\n",
        "        self.layer_norm_2 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        self.mlp = # ... TO DO\n",
        "\n",
        "    def forward(self, x):\n",
        "        inp_x = self.layer_norm_1(x)\n",
        "        x = x + self.attn(inp_x, inp_x, inp_x)[0] #nn.MultiheadAttention expects input shapes 3x(L,B,F) and output\n",
        "        x = # ... TO DO\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 2:** for the MyTransformer class write the forward(self, x) method.\n",
        "\n",
        "**Tipp:**\n",
        "the sequence of operation on the input *x* are:\n",
        "* project *x* into the embed_dim space\n",
        "* apply dropout\n",
        "* apply the transformer (remember to use *x.transpose(0, 1)* as the *nn.MultiheadAttention* expects input shape (L,B,F) and not (B,L,F)\n",
        "* apply the mlp head for the classification"
      ],
      "metadata": {
        "id": "j64LDA49K27C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyTransformer(nn.Module):\n",
        "    #  Classifier based on a Transformer encoder architecture implementation\n",
        "\n",
        "    #  structure:\n",
        "    #   MHA: pre layer normalization (see Ruibin Xiong et al. (2020)) + multi-head attention (pytorch implementation) + layer normalization\n",
        "    #   MLP: dense + gelu + droput + dense + dropout\n",
        "\n",
        "    #  arguments:\n",
        "    #   input_dim  - Dimensionality of input feature vectors (jet features)\n",
        "    #   embed_dim  - Dimensionality of embedding in input to the Transformer\n",
        "    #   hidden_dim - Dimensionality of hidden layer in feed-forward network\n",
        "    #   num_heads  - Number of heads to use in the Multi-Head Attention block\n",
        "    #   num_layers - Number of layers to use in the Transformer\n",
        "    #   num_classes- Number of categories for the classification task\n",
        "    #   dropout    - Amount of dropout to apply in the feed-forward network and in the input\n",
        "\n",
        "    def __init__(self, input_dim, embed_dim, hidden_dim, num_heads, num_layers, num_classes, dropout=0.0):\n",
        "        super(MyTransformer, self).__init__()\n",
        "\n",
        "        # input layer (a dense MLP projecting the input in a embed_dim embedding space)\n",
        "        self.input_layer = nn.Sequential(\n",
        "            nn.Linear(input_dim,128),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(128,512),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(512,embed_dim),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        # Transformer encoder: stack of num_layers Attention Blocks (embed_dim -> embed_dim)\n",
        "        self.transformer = nn.Sequential(*[AttentionBlock(embed_dim, hidden_dim, num_heads, dropout=dropout) for _ in range(num_layers)])\n",
        "\n",
        "        # MLP Classifier (embed_dim -> num_classes)\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.Linear(embed_dim, num_classes)\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # project input into the embed_dim space\n",
        "        x = # ... TO DO\n",
        "\n",
        "        # Apply Transformer\n",
        "        x = # ... TO DO\n",
        "\n",
        "        # Classifier prediction\n",
        "        out = # ... TO DO\n",
        "        return out"
      ],
      "metadata": {
        "id": "zKVPI8y4TUpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate the model\n",
        "model_kwargs={\n",
        "              'input_dim': 16,\n",
        "              'embed_dim': 128,\n",
        "              'hidden_dim': 256,\n",
        "              'num_heads': 8,\n",
        "              'num_layers': 8,\n",
        "              'num_classes': 5,\n",
        "              'dropout': 0.30\n",
        "             }\n",
        "\n",
        "model = MyTransformer(**model_kwargs)"
      ],
      "metadata": {
        "id": "i2BmhaXZ9RgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print model structure\n",
        "\n",
        "print(model)\n",
        "\n",
        "from torchsummary import summary\n",
        "if torch.cuda.is_available():\n",
        "  summary(model.cuda(), input_size=(100,16))\n",
        "else:\n",
        "  summary(model, input_size=(100,16))"
      ],
      "metadata": {
        "id": "Wklpd2I6CKbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:** test the model on one batch to check everything is ok before training it\n",
        "\n",
        "**Tipp:**\n",
        "take one mini batch from the *train_loader* using *next(iter(loaeder))*, move model and tensors to GPU (using *tensor/model.to(device))*, test the model prediction with *model(input batch)*, and print the shape of the input and output"
      ],
      "metadata": {
        "id": "obz1K7FbMX3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model on one batch to check everything is ok before training it\n",
        "\n",
        "# ... TODO"
      ],
      "metadata": {
        "id": "d7pBdPeRkEBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Procedure\n",
        "\n",
        "We are now ready to complete the model by defining the loss function, the accuracy metric to monitor the training of the classifier, and the optmizer + learning rate scheduler.\n",
        "\n",
        "Write two simple procedures to train and test the model on the training and test dataset, respectively.\n",
        "\n",
        "If you are not new to PyTorch, this scheme should appear familiar to you. Otherwise, the PyTorch web site provides [a good introduction on how to train a neural network in PyTorch](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a-loss-function-and-optimizer)."
      ],
      "metadata": {
        "id": "Lyp1MepbBfQe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:** include an accuracy function to monitor the accuracy during training above with the equivalent available in the torchmetrics library\n",
        "\n",
        "**Tipp:**\n",
        "use the trochmetrics library, see the example *[PyTorch_SimpleMLP_Example.ipynb](https://github.com/stefanogiagu/corso_AML_2023/blob/main/notebooks/PyTorch_SimpleMLP_Example.ipynb)* we have discusses in one of the first lectures, and use *torchmetrics.classification.MulticlassAccuracy* method"
      ],
      "metadata": {
        "id": "CSdOMc5QNkVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install torchmetrics: collection of useful PyTorch metrics implementations and an easy-to-use API to create custom metrics]\n",
        "%pip install torchmetrics"
      ],
      "metadata": {
        "id": "NMf9xQdr2HQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loss\n",
        "loss_func = nn.CrossEntropyLoss() #cross entropy loss\n",
        "\n",
        "#metric accuracy from torchmetrics\n",
        "import torchmetrics\n",
        "from torchmetrics.classification import MulticlassAccuracy\n",
        "metric_func = MulticlassAccuracy(num_classes=5)\n",
        "metric_func = metric_func.to(device)\n",
        "\n",
        "# optimizer + lr schedular\n",
        "from torch import optim\n",
        "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# scheduler for step decay lr schedule\n",
        "lr_scheduler = optim.lr_scheduler.MultiStepLR(opt, milestones=[20,30,35], gamma=0.2)"
      ],
      "metadata": {
        "id": "YWSguEkPknur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checkpoints (to save model parameters during training)\n",
        "\n",
        "# this is implemented by writing a python class that uses the torch.save method\n",
        "\n",
        "class SaveBestModel:\n",
        "    def __init__(self, best_valid_loss=float('inf')): #object initialized with best_loss = +infinite\n",
        "        self.best_valid_loss = best_valid_loss\n",
        "\n",
        "    def __call__(\n",
        "        self, current_valid_loss,\n",
        "        epoch, model, optimizer, criterion, metric,\n",
        "    ):\n",
        "        if current_valid_loss < self.best_valid_loss:\n",
        "            self.best_valid_loss = current_valid_loss\n",
        "            print(f\"\\nBest validation loss: {self.best_valid_loss}\")\n",
        "            print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
        "            # method to save a model (the state_dict: a python dictionary object that\n",
        "            # maps each layer to its parameter tensor) and other useful parametrers\n",
        "            # see: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
        "            torch.save({\n",
        "                'epoch': epoch+1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': criterion,\n",
        "                'metric': metric,\n",
        "                }, 'best_model.pth')"
      ],
      "metadata": {
        "id": "qVAE2etRkyiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:** add the validation part to the training loop shown below ..."
      ],
      "metadata": {
        "id": "-e_LTyCtzWFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in pytorch you are responsible of writing the training loop, this can be done by implementig specific\n",
        "# python functions for the training and validation steps, or just, like in this example, by using a simple plain\n",
        "# python loop\n",
        "\n",
        "#training loop\n",
        "\n",
        "epochs = 40 #number of epochs (~30\"/epoch on T4 GPU in this hands-on)\n",
        "\n",
        "import time\n",
        "\n",
        "save_best_model = SaveBestModel() #initialize checkpoint function\n",
        "\n",
        "# dfine python lists to save loss and metric history\n",
        "hist_loss = []\n",
        "hist_metric = []\n",
        "hist_vloss = []\n",
        "hist_vmetric = []\n",
        "\n",
        "#loop over epochs\n",
        "for epoch in range(epochs):\n",
        "    t0 = time.time()\n",
        "\n",
        "    #training step\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0.0\n",
        "    train_metric = 0.0\n",
        "    counter = 0\n",
        "    for xb, yb in train_loader: #takes a batch from the train dataloader\n",
        "        counter += 1\n",
        "        xb=xb.type(torch.float).to(device) #move troch tensors to device (cpu or GPU)\n",
        "        yb=yb.type(torch.long).to(device)\n",
        "\n",
        "        pred = model(xb) #get prediction for batch\n",
        "        loss = loss_func(pred, yb) #compute loss\n",
        "        metric = metric_func(pred, yb) #compute accuracy\n",
        "\n",
        "        train_loss += loss.item() #update total loss\n",
        "        train_metric += metric.item() #update total metric\n",
        "\n",
        "        # backpropagation\n",
        "        loss.backward()\n",
        "        # update weights\n",
        "        opt.step()\n",
        "        # set to zero gradients for the next step\n",
        "        opt.zero_grad()\n",
        "\n",
        "    # normalize loss and metric by number of batches\n",
        "    train_loss = train_loss/(counter)\n",
        "    train_metric = train_metric/(counter)\n",
        "\n",
        "    # update history\n",
        "    hist_loss.append(train_loss)\n",
        "    hist_metric.append(train_metric)\n",
        "\n",
        "    # evaluation step (same as training but w/o backpropagation)\n",
        "\n",
        "    # ... TODO\n",
        "\n",
        "    #save best model\n",
        "    save_best_model(vali_loss, epoch, model, opt, loss_func, metric_func)\n",
        "\n",
        "    elapsed_time = time.time()-t0\n",
        "    current_lr = lr_scheduler.get_last_lr()[0]\n",
        "    print(\"epoch: %d, time(s): %.2f, train loss: %.6f, train metric: %.6f, vali loss: %.6f, vali metric: %.6f,  lr : %1.2e\" % (epoch+1, elapsed_time, train_loss, train_metric, vali_loss, vali_metric,current_lr))\n",
        "\n",
        "    # update learning rate schedule\n",
        "    lr_scheduler.step()"
      ],
      "metadata": {
        "id": "JJafF4smlGa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:** plot with matplotlib loss and accuracy VS #epochs for train and validation sets"
      ],
      "metadata": {
        "id": "UCFDR-MARCH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training results (loss and accuracy vs epoch)\n",
        "\n",
        "# ... TODO"
      ],
      "metadata": {
        "id": "gAAROdgKV8na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the best model\n",
        "checkpoint = torch.load('./best_model.pth')\n",
        "print('Best model at epoch: ', checkpoint['epoch'])\n",
        "\n",
        "model = MyTransformer(**model_kwargs)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "Pfx_hAbaWLKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise:** loop over the test set and:\n",
        "* compute the average accuracy\n",
        "* save the predicted probability for each class in a torch tensor *pred_prob* of size *(test_set_events, 5)*\n",
        "* save the predicted class in a torch tensor *pred_val* of size *(test_set_events,)*\n",
        "* save the true class in in a torch tensor *ground_truth* of size *(test_set_events,)*\n",
        "\n",
        "**Tipp:**\n",
        "write a loop similar to the one used in the validation step of the training loop. Put tensors on GPU to speedup the computation.\n",
        "\n",
        "NOTE:\n",
        "* example to create an empty torch tensor on the GPU: *torch.empty(size=(0,5), device=device)*\n",
        "* example on how to concatenate two torch tensors along first dimension: *torch.cat((pred_prob, pre), dim=0)*"
      ],
      "metadata": {
        "id": "aHTWJyknRnu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inference on test set\n",
        "pred_prob = # ... TODO\n",
        "pred_val = # ... TODO\n",
        "ground_truth = # ... TODO\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# ... TODO\n",
        "\n",
        "predict_val = pred_val.cpu().data.numpy()\n",
        "predict_prob = pred_prob.cpu().data.numpy()\n",
        "true_val = ground_truth.cpu().data.numpy()\n",
        "\n",
        "print('test loss: ', test_loss)\n",
        "print('test average accuracy: ', test_metric)"
      ],
      "metadata": {
        "id": "E7SVN0FEYjwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# print ROC curves\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "auc1 = {}\n",
        "plt.figure()\n",
        "for i, label in enumerate(labels):\n",
        "        fpr[label], tpr[label], threshold = roc_curve((true_val==i), predict_prob[:,i])\n",
        "        auc1[label] = auc(fpr[label], tpr[label])\n",
        "        plt.plot(tpr[label],fpr[label],label='%s tagger, auc = %.1f%%'%(label,auc1[label]*100.))\n",
        "plt.semilogy()\n",
        "plt.xlabel(\"sig. efficiency\")\n",
        "plt.ylabel(\"bkg. mistag rate\")\n",
        "plt.ylim(0.001,1)\n",
        "plt.grid(True)\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HOZoH2ZQkkZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to print a formatted confusion matrix\n",
        "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
        "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
        "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
        "    empty_cell = \" \" * columnwidth\n",
        "    # Print header\n",
        "    print(\"    \" + empty_cell, end=\" \")\n",
        "    for label in labels:\n",
        "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
        "    print()\n",
        "\n",
        "    # Print rows\n",
        "    for i, label1 in enumerate(labels):\n",
        "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
        "        for j in range(len(labels)):\n",
        "            cell = \"%{0}.2f\".format(columnwidth) % cm[i, j]\n",
        "            if hide_zeroes:\n",
        "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
        "            if hide_diagonal:\n",
        "                cell = cell if i != j else empty_cell\n",
        "            if hide_threshold:\n",
        "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
        "            print(cell, end=\" \")\n",
        "        print()"
      ],
      "metadata": {
        "id": "RkaVNQgWzNoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "c_mat = confusion_matrix(true_val, predict_val, normalize='true')\n",
        "print(\"Confusion Matrix:\")\n",
        "print(\"\")\n",
        "print_cm(c_mat,labels)"
      ],
      "metadata": {
        "id": "UpWsmhGmqTgm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}